{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General scikit-learn grid search tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "import sklearn\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris.data.shape, iris.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "\n",
    "X_test.shape, y_test.shape\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "scores  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2f} (+/- {1:.2f})\".format(scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96658312, 1.        , 0.96658312, 0.96658312, 1.        ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "scores = cross_val_score(\n",
    "    clf, iris.data, iris.target, cv=5, scoring='f1_macro')\n",
    "scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'brier_score_loss',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'mutual_info_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ShuffleSplit in module sklearn.model_selection._split:\n",
      "\n",
      "class ShuffleSplit(BaseShuffleSplit)\n",
      " |  ShuffleSplit(n_splits=10, test_size='default', train_size=None, random_state=None)\n",
      " |  \n",
      " |  Random permutation cross-validator\n",
      " |  \n",
      " |  Yields indices to split data into training and test sets.\n",
      " |  \n",
      " |  Note: contrary to other cross-validation strategies, random splits\n",
      " |  do not guarantee that all folds will be different, although this is\n",
      " |  still very likely for sizeable datasets.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_splits : int, default 10\n",
      " |      Number of re-shuffling & splitting iterations.\n",
      " |  \n",
      " |  test_size : float, int, None, default=0.1\n",
      " |      If float, should be between 0.0 and 1.0 and represent the proportion\n",
      " |      of the dataset to include in the test split. If int, represents the\n",
      " |      absolute number of test samples. If None, the value is set to the\n",
      " |      complement of the train size. By default (the parameter is\n",
      " |      unspecified), the value is set to 0.1.\n",
      " |      The default will change in version 0.21. It will remain 0.1 only\n",
      " |      if ``train_size`` is unspecified, otherwise it will complement\n",
      " |      the specified ``train_size``.\n",
      " |  \n",
      " |  train_size : float, int, or None, default=None\n",
      " |      If float, should be between 0.0 and 1.0 and represent the\n",
      " |      proportion of the dataset to include in the train split. If\n",
      " |      int, represents the absolute number of train samples. If None,\n",
      " |      the value is automatically set to the complement of the test size.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.model_selection import ShuffleSplit\n",
      " |  >>> X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [3, 4], [5, 6]])\n",
      " |  >>> y = np.array([1, 2, 1, 2, 1, 2])\n",
      " |  >>> rs = ShuffleSplit(n_splits=5, test_size=.25, random_state=0)\n",
      " |  >>> rs.get_n_splits(X)\n",
      " |  5\n",
      " |  >>> print(rs)\n",
      " |  ShuffleSplit(n_splits=5, random_state=0, test_size=0.25, train_size=None)\n",
      " |  >>> for train_index, test_index in rs.split(X):\n",
      " |  ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      " |  ...  # doctest: +ELLIPSIS\n",
      " |  TRAIN: [1 3 0 4] TEST: [5 2]\n",
      " |  TRAIN: [4 0 2 5] TEST: [1 3]\n",
      " |  TRAIN: [1 2 4 0] TEST: [3 5]\n",
      " |  TRAIN: [3 4 1 0] TEST: [5 2]\n",
      " |  TRAIN: [3 5 1 0] TEST: [2 4]\n",
      " |  >>> rs = ShuffleSplit(n_splits=5, train_size=0.5, test_size=.25,\n",
      " |  ...                   random_state=0)\n",
      " |  >>> for train_index, test_index in rs.split(X):\n",
      " |  ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      " |  ...  # doctest: +ELLIPSIS\n",
      " |  TRAIN: [1 3 0] TEST: [5 2]\n",
      " |  TRAIN: [4 0 2] TEST: [1 3]\n",
      " |  TRAIN: [1 2 4] TEST: [3 5]\n",
      " |  TRAIN: [3 4 1] TEST: [5 2]\n",
      " |  TRAIN: [3 5 1] TEST: [2 4]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ShuffleSplit\n",
      " |      BaseShuffleSplit\n",
      " |      abc.NewBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseShuffleSplit:\n",
      " |  \n",
      " |  __init__(self, n_splits=10, test_size='default', train_size=None, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  get_n_splits(self, X=None, y=None, groups=None)\n",
      " |      Returns the number of splitting iterations in the cross-validator\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      y : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      n_splits : int\n",
      " |          Returns the number of splitting iterations in the cross-validator.\n",
      " |  \n",
      " |  split(self, X, y=None, groups=None)\n",
      " |      Generate indices to split data into training and test set.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Training data, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          The target variable for supervised learning problems.\n",
      " |      \n",
      " |      groups : array-like, with shape (n_samples,), optional\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      train : ndarray\n",
      " |          The training set indices for that split.\n",
      " |      \n",
      " |      test : ndarray\n",
      " |          The testing set indices for that split.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Randomized CV splitters may return different results for each call of\n",
      " |      split. You can make the results identical by setting ``random_state``\n",
      " |      to an integer.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from abc.NewBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "help(ShuffleSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.986 (+/-0.016) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.959 (+/-0.029) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.017) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.026) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.017) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.025) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.017) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.025) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.975 (+/-0.014) for {'C': 1, 'kernel': 'linear'}\n",
      "0.975 (+/-0.014) for {'C': 10, 'kernel': 'linear'}\n",
      "0.975 (+/-0.014) for {'C': 100, 'kernel': 'linear'}\n",
      "0.975 (+/-0.014) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        89\n",
      "           1       0.97      1.00      0.98        90\n",
      "           2       0.99      0.98      0.98        92\n",
      "           3       1.00      0.99      0.99        93\n",
      "           4       1.00      1.00      1.00        76\n",
      "           5       0.99      0.98      0.99       108\n",
      "           6       0.99      1.00      0.99        89\n",
      "           7       0.99      1.00      0.99        78\n",
      "           8       1.00      0.98      0.99        92\n",
      "           9       0.99      0.99      0.99        92\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       899\n",
      "   macro avg       0.99      0.99      0.99       899\n",
      "weighted avg       0.99      0.99      0.99       899\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.986 (+/-0.019) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.957 (+/-0.029) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.019) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.981 (+/-0.028) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.019) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.981 (+/-0.026) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.019) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.981 (+/-0.026) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.972 (+/-0.012) for {'C': 1, 'kernel': 'linear'}\n",
      "0.972 (+/-0.012) for {'C': 10, 'kernel': 'linear'}\n",
      "0.972 (+/-0.012) for {'C': 100, 'kernel': 'linear'}\n",
      "0.972 (+/-0.012) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        89\n",
      "           1       0.97      1.00      0.98        90\n",
      "           2       0.99      0.98      0.98        92\n",
      "           3       1.00      0.99      0.99        93\n",
      "           4       1.00      1.00      1.00        76\n",
      "           5       0.99      0.98      0.99       108\n",
      "           6       0.99      1.00      0.99        89\n",
      "           7       0.99      1.00      0.99        78\n",
      "           8       1.00      0.98      0.99        92\n",
      "           9       0.99      0.99      0.99        92\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       899\n",
      "   macro avg       0.99      0.99      0.99       899\n",
      "weighted avg       0.99      0.99      0.99       899\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Loading the Digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Note the problem is too easy: the hyperparameter plateau is too flat and the\n",
    "# output model is the same for precision and recall with ties in quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function classification_report in module sklearn.metrics.classification:\n",
      "\n",
      "classification_report(y_true, y_pred, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False)\n",
      "    Build a text report showing the main classification metrics\n",
      "    \n",
      "    Read more in the :ref:`User Guide <classification_report>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "        Ground truth (correct) target values.\n",
      "    \n",
      "    y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "        Estimated targets as returned by a classifier.\n",
      "    \n",
      "    labels : array, shape = [n_labels]\n",
      "        Optional list of label indices to include in the report.\n",
      "    \n",
      "    target_names : list of strings\n",
      "        Optional display names matching the labels (same order).\n",
      "    \n",
      "    sample_weight : array-like of shape = [n_samples], optional\n",
      "        Sample weights.\n",
      "    \n",
      "    digits : int\n",
      "        Number of digits for formatting output floating point values.\n",
      "        When ``output_dict`` is ``True``, this will be ignored and the\n",
      "        returned values will not be rounded.\n",
      "    \n",
      "    output_dict : bool (default = False)\n",
      "        If True, return output as dict\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    report : string / dict\n",
      "        Text summary of the precision, recall, F1 score for each class.\n",
      "        Dictionary returned if output_dict is True. Dictionary has the\n",
      "        following structure::\n",
      "    \n",
      "            {'label 1': {'precision':0.5,\n",
      "                         'recall':1.0,\n",
      "                         'f1-score':0.67,\n",
      "                         'support':1},\n",
      "             'label 2': { ... },\n",
      "              ...\n",
      "            }\n",
      "    \n",
      "        The reported averages include micro average (averaging the\n",
      "        total true positives, false negatives and false positives), macro\n",
      "        average (averaging the unweighted mean per label), weighted average\n",
      "        (averaging the support-weighted mean per label) and sample average\n",
      "        (only for multilabel classification). See also\n",
      "        :func:`precision_recall_fscore_support` for more details on averages.\n",
      "    \n",
      "        Note that in binary classification, recall of the positive class\n",
      "        is also known as \"sensitivity\"; recall of the negative class is\n",
      "        \"specificity\".\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.metrics import classification_report\n",
      "    >>> y_true = [0, 1, 2, 2, 2]\n",
      "    >>> y_pred = [0, 0, 2, 2, 1]\n",
      "    >>> target_names = ['class 0', 'class 1', 'class 2']\n",
      "    >>> print(classification_report(y_true, y_pred, target_names=target_names))\n",
      "                  precision    recall  f1-score   support\n",
      "    <BLANKLINE>\n",
      "         class 0       0.50      1.00      0.67         1\n",
      "         class 1       0.00      0.00      0.00         1\n",
      "         class 2       1.00      0.67      0.80         3\n",
      "    <BLANKLINE>\n",
      "       micro avg       0.60      0.60      0.60         5\n",
      "       macro avg       0.50      0.56      0.49         5\n",
      "    weighted avg       0.70      0.60      0.61         5\n",
      "    <BLANKLINE>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Booster parameters\n",
    "- $\\eta$ `eta` is the learning rate typical 0.01 - 0.2\n",
    "- `min_child_weight` tune using CV. Defines the minimum sum of weights of all observations required in a child. Used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree. Too high values can lead to under-fitting.\n",
    "- `max_depth` tune CV, typical 3 - 10\n",
    "- $\\gamma$ `gamma` A node is split only when the resulting split gives a positive reduction in the loss function. Gamma specifies the minimum loss reduction required to make a split. Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned.\n",
    "- `subsample` [default=1] Denotes the fraction of observations to be randomly samples for each tree. Typical values: 0.5 - 1.\n",
    "- `colsample_bytree` [default=1] Denotes the fraction of columns to be randomly samples for each tree. Typical values: 0.5 - 1.\n",
    "- $\\lambda$ `lambda` [default=1] L2 regularization term on weights (analogous to Ridge regression). This used to handle the regularization part of XGBoost. Though many data scientists don’t use it often, it should be explored to reduce overfitting.\n",
    "- $\\alpha$ `alpha` [default=0] L1 regularization term on weight (analogous to Lasso regression). Can be used in case of very high dimensionality so that the algorithm runs faster when implemented.\n",
    "- `scale_pos_weight` [default=1] A value greater than 0 should be used in case of high class imbalance as it helps in faster convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Task Parameters\n",
    "\n",
    "These parameters are used to define the optimization objective the metric to be calculated at each step.\n",
    "\n",
    "- `objective` [default=reg:linear] This defines the loss function to be minimized. Mostly used values are:\n",
    "    - binary:logistic –logistic regression for binary classification, returns predicted probability (not class)\n",
    "    - multi:softmax –multiclass classification using the softmax objective, returns predicted class (not probabilities), you also need to set an additional num_class (number of classes) parameter defining the number of unique classes\n",
    "    - multi:softprob –same as softmax, but returns predicted probability of each data point belonging to each class.\n",
    "- `eval_metric` [ default according to objective ] The metric to be used for validation data. The default values are rmse for regression and error for classification. Typical values are:\n",
    "    - rmse – root mean square error\n",
    "    - mae – mean absolute error\n",
    "    - logloss – negative log-likelihood\n",
    "    - error – Binary classification error rate (0.5 threshold)\n",
    "    - merror – Multiclass classification error rate\n",
    "    - mlogloss – Multiclass logloss\n",
    "    - auc: Area under the curve\n",
    "- `seed` [default=0] The random number seed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `xgb` – this is the direct xgboost library. I will use a specific function “cv” from this library\n",
    "2. `XGBClassifier` – this is an sklearn wrapper for XGBoost. This allows us to use sklearn’s Grid Search with parallel processing in the same way we did for GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'Tilii: https://kaggle.com/tilii7' \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
